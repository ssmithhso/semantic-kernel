{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68e1c158",
   "metadata": {},
   "source": [
    "# Building Semantic Memory with Embeddings\n",
    "\n",
    "So far, we've mostly been treating the kernel as a stateless orchestration engine.\n",
    "We send text into a model API and receive text out.\n",
    "\n",
    "In a [previous notebook](04-context-variables-chat.ipynb), we used `context variables` to pass in additional\n",
    "text into prompts to enrich them with more context. This allowed us to create a basic chat experience.\n",
    "\n",
    "However, if you solely relied on context variables, you would quickly realize that eventually your prompt\n",
    "would grow so large that you would run into the model's token limit. What we need is a way to persist state\n",
    "and build both short-term and long-term memory to empower even more intelligent applications.\n",
    "\n",
    "To do this, we dive into the key concept of `Semantic Memory` in the Semantic Kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a77bdf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantic-kernel==0.9.4b1 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (0.9.4b1)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.8 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (3.9.3)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (0.7.1)\n",
      "Requirement already satisfied: grpcio>=1.50.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (1.62.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (3.1.3)\n",
      "Requirement already satisfied: motor<4.0.0,>=3.3.2 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (3.4.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.25 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (1.14.3)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (0.19.0)\n",
      "Requirement already satisfied: prance<24.0.0.0,>=23.6.21.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (23.6.21.0)\n",
      "Requirement already satisfied: pybars4<0.10.0,>=0.9.13 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (0.9.13)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (2.6.4)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (1.0.1)\n",
      "Requirement already satisfied: regex<2024.0.0,>=2023.6.3 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (2023.12.25)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel==0.9.4b1) (1.12.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.4b1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.4b1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.4b1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.4b1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.4b1) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from jinja2<4.0.0,>=3.1.3->semantic-kernel==0.9.4b1) (2.1.5)\n",
      "Requirement already satisfied: pymongo<5,>=4.5 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from motor<4.0.0,>=3.3.2->semantic-kernel==0.9.4b1) (4.6.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.4b1) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.4b1) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.4b1) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.4b1) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.4b1) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.4b1) (4.10.0)\n",
      "Requirement already satisfied: isodate in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (0.6.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (4.21.1)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (0.3.2)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (10.2.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (0.6.2)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (0.7.1)\n",
      "Requirement already satisfied: parse in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (1.20.1)\n",
      "Requirement already satisfied: werkzeug in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (3.0.1)\n",
      "Requirement already satisfied: chardet>=3.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.4b1) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.4b1) (0.18.6)\n",
      "Requirement already satisfied: requests>=2.25 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.4b1) (2.31.0)\n",
      "Requirement already satisfied: six~=1.15 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.4b1) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.4b1) (24.0)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from pybars4<0.10.0,>=0.9.13->semantic-kernel==0.9.4b1) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from pydantic<3,>=2->semantic-kernel==0.9.4b1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from pydantic<3,>=2->semantic-kernel==0.9.4b1) (2.16.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0->semantic-kernel==0.9.4b1) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.4b1) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.4b1) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.4b1) (0.14.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (0.31.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (0.18.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (6.0.1)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (0.4.3)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel==0.9.4b1) (1.10.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from pymongo<5,>=4.5->motor<4.0.0,>=3.3.2->semantic-kernel==0.9.4b1) (2.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.4b1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.4b1) (2.2.1)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from ruamel.yaml>=0.17.10->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.4b1) (0.2.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\samuelsmith\\semantic-kernel\\.venv\\lib\\site-packages (from tqdm>4->openai>=1.0->semantic-kernel==0.9.4b1) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install semantic-kernel==0.9.4b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "508ad44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    OpenAIChatCompletion,\n",
    "    OpenAITextEmbedding,\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")\n",
    "from semantic_kernel.prompt_template.prompt_template_config import PromptTemplateConfig\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b95af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services import Service\n",
    "\n",
    "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
    "selectedService = Service.AzureOpenAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8ddffc1",
   "metadata": {},
   "source": [
    "In order to use memory, we need to instantiate the Kernel with a Memory Storage\n",
    "and an Embedding service. In this example, we make use of the `VolatileMemoryStore` which can be thought of as a temporary in-memory storage. This memory is not written to disk and is only available during the app session.\n",
    "\n",
    "When developing your app you will have the option to plug in persistent storage like Azure AI Search, Azure Cosmos Db, PostgreSQL, SQLite, etc. Semantic Memory allows also to index external data sources, without duplicating all the information as you will see further down in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f8dcbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='TextMemoryPlugin', description=None, functions={'recall': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='recall', plugin_name='TextMemoryPlugin', description='Recall a fact from the long term memory', parameters=[KernelParameterMetadata(name='ask', description='The information to retrieve', default_value=None, type_='str', is_required=True, type_object=<class 'str'>), KernelParameterMetadata(name='collection', description='The collection to search for information.', default_value='generic', type_='str', is_required=False, type_object=<class 'str'>), KernelParameterMetadata(name='relevance', description='The relevance score, from 0.0 to 1.0; 1.0 means perfect match', default_value=0.75, type_='float', is_required=False, type_object=<class 'float'>), KernelParameterMetadata(name='limit', description='The maximum number of relevant memories to recall.', default_value=1, type_='int', is_required=False, type_object=<class 'int'>)], is_prompt=False, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=None)), method=<bound method TextMemoryPlugin.recall of TextMemoryPlugin(memory=SemanticTextMemory())>, stream_method=None), 'save': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='save', plugin_name='TextMemoryPlugin', description='Save information to semantic memory', parameters=[KernelParameterMetadata(name='text', description='The information to save.', default_value=None, type_='str', is_required=True, type_object=<class 'str'>), KernelParameterMetadata(name='key', description='The unique key to associate with the information.', default_value=None, type_='str', is_required=True, type_object=<class 'str'>), KernelParameterMetadata(name='collection', description='The collection to save the information.', default_value='generic', type_='str', is_required=False, type_object=<class 'str'>)], is_prompt=False, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='', is_required=True, type_object=None)), method=<bound method TextMemoryPlugin.save of TextMemoryPlugin(memory=SemanticTextMemory())>, stream_method=None)})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = sk.Kernel()\n",
    "\n",
    "chat_service_id = \"chat\"\n",
    "\n",
    "\n",
    "deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "# next line assumes chat deployment name is \"turbo\", adjust the deployment name to the value of your chat model if needed\n",
    "azure_chat_service = AzureChatCompletion(\n",
    "    service_id=chat_service_id, deployment_name=\"hso_gpt4\", endpoint=endpoint, api_key=api_key\n",
    ")\n",
    "\n",
    "embedding_name = \"text-embedding-ada-002\"\n",
    "# next line assumes embeddings deployment name is \"text-embedding\", adjust the deployment name to the value of your chat model if needed\n",
    "embedding_gen = AzureTextEmbedding(deployment_name=embedding_name, endpoint=endpoint, api_key=api_key)\n",
    "kernel.add_service(azure_chat_service)\n",
    "kernel.add_service(embedding_gen)\n",
    "\n",
    "memory = SemanticTextMemory(storage=sk.memory.VolatileMemoryStore(), embeddings_generator=embedding_gen)\n",
    "kernel.import_plugin_from_object(TextMemoryPlugin(memory), \"TextMemoryPlugin\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7fefb6a",
   "metadata": {},
   "source": [
    "At its core, Semantic Memory is a set of data structures that allow you to store the meaning of text that come from different data sources, and optionally to store the source text too. These texts can be from the web, e-mail providers, chats, a database, or from your local directory, and are hooked up to the Semantic Kernel through data source connectors.\n",
    "\n",
    "The texts are embedded or compressed into a vector of floats representing mathematically the texts' contents and meaning. You can read more about embeddings [here](https://aka.ms/sk/embeddings).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a7e7ca4",
   "metadata": {},
   "source": [
    "### Manually adding memories\n",
    "\n",
    "Let's create some initial memories \"About Me\". We can add memories to our `VolatileMemoryStore` by using `SaveInformationAsync`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d096504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = \"generic\"\n",
    "\n",
    "\n",
    "async def populate_memory(memory: SemanticTextMemory) -> None:\n",
    "    # Add some documents to the semantic memory\n",
    "    await memory.save_information(collection=collection_id, id=\"info1\", text=\"Your budget for 2024 is $100,000\")\n",
    "    await memory.save_information(collection=collection_id, id=\"info2\", text=\"Your savings from 2023 are $50,000\")\n",
    "    await memory.save_information(collection=collection_id, id=\"info3\", text=\"Your investments are $80,000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5338d3ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceResponseException",
     "evalue": "(\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_text_embedding.AzureTextEmbedding'> service failed to generate embeddings\", AuthenticationError(\"Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\SamuelSmith\\semantic-kernel\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:80\u001b[0m, in \u001b[0;36mOpenAIHandler._send_embedding_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings\u001b[38;5;241m.\u001b[39mprepare_settings_dict())\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_usage(response)\n",
      "File \u001b[1;32mc:\\Users\\SamuelSmith\\semantic-kernel\\.venv\\Lib\\site-packages\\openai\\resources\\embeddings.py:214\u001b[0m, in \u001b[0;36mAsyncEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[0;32m    217\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    218\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[0;32m    219\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[0;32m    220\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[0;32m    221\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    222\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    223\u001b[0m     ),\n\u001b[0;32m    224\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[0;32m    225\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\SamuelSmith\\semantic-kernel\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1738\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1735\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1736\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1737\u001b[0m )\n\u001b[1;32m-> 1738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[1;32mc:\\Users\\SamuelSmith\\semantic-kernel\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1441\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1432\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m   1433\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1434\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     remaining_retries: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1440\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m-> 1441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1442\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1443\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1444\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1445\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1446\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m   1447\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SamuelSmith\\semantic-kernel\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1532\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1531\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1535\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1536\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1539\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1540\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mServiceResponseException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m populate_memory(memory)\n",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m, in \u001b[0;36mpopulate_memory\u001b[1;34m(memory)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpopulate_memory\u001b[39m(memory: SemanticTextMemory) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Add some documents to the semantic memory\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m memory\u001b[38;5;241m.\u001b[39msave_information(collection\u001b[38;5;241m=\u001b[39mcollection_id, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo1\u001b[39m\u001b[38;5;124m\"\u001b[39m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour budget for 2024 is $100,000\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m memory\u001b[38;5;241m.\u001b[39msave_information(collection\u001b[38;5;241m=\u001b[39mcollection_id, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo2\u001b[39m\u001b[38;5;124m\"\u001b[39m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour savings from 2023 are $50,000\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m memory\u001b[38;5;241m.\u001b[39msave_information(collection\u001b[38;5;241m=\u001b[39mcollection_id, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo3\u001b[39m\u001b[38;5;124m\"\u001b[39m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour investments are $80,000\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\SamuelSmith\\semantic-kernel\\.venv\\Lib\\site-packages\\semantic_kernel\\memory\\semantic_text_memory.py:58\u001b[0m, in \u001b[0;36mSemanticTextMemory.save_information\u001b[1;34m(self, collection, text, id, description, additional_metadata)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage\u001b[38;5;241m.\u001b[39mdoes_collection_exist(collection_name\u001b[38;5;241m=\u001b[39mcollection):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage\u001b[38;5;241m.\u001b[39mcreate_collection(collection_name\u001b[38;5;241m=\u001b[39mcollection)\n\u001b[1;32m---> 58\u001b[0m embedding \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embeddings_generator\u001b[38;5;241m.\u001b[39mgenerate_embeddings([text]))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     59\u001b[0m data \u001b[38;5;241m=\u001b[39m MemoryRecord\u001b[38;5;241m.\u001b[39mlocal_record(\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[0;32m     61\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage\u001b[38;5;241m.\u001b[39mupsert(collection_name\u001b[38;5;241m=\u001b[39mcollection, record\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\SamuelSmith\\semantic-kernel\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_text_embedding_base.py:38\u001b[0m, in \u001b[0;36mOpenAITextEmbeddingBase.generate_embeddings\u001b[1;34m(self, texts, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m     batch \u001b[38;5;241m=\u001b[39m texts[i : i \u001b[38;5;241m+\u001b[39m batch_size]  \u001b[38;5;66;03m# noqa: E203\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     settings\u001b[38;5;241m.\u001b[39minput \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m---> 38\u001b[0m     raw_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_embedding_request(\n\u001b[0;32m     39\u001b[0m         settings\u001b[38;5;241m=\u001b[39msettings,\n\u001b[0;32m     40\u001b[0m     )\n\u001b[0;32m     41\u001b[0m     raw_embeddings\u001b[38;5;241m.\u001b[39mextend(raw_embedding)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array(raw_embeddings)\n",
      "File \u001b[1;32mc:\\Users\\SamuelSmith\\semantic-kernel\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:86\u001b[0m, in \u001b[0;36mOpenAIHandler._send_embedding_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [array(x\u001b[38;5;241m.\u001b[39membedding) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata]\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service failed to generate embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m         ex,\n\u001b[0;32m     89\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;31mServiceResponseException\u001b[0m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_text_embedding.AzureTextEmbedding'> service failed to generate embeddings\", AuthenticationError(\"Error code: 401 - {'statusCode': 401, 'message': 'Unauthorized. Access token is missing, invalid, audience is incorrect (https://cognitiveservices.azure.com), or have expired.'}\"))"
     ]
    }
   ],
   "source": [
    "await populate_memory(memory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2calf857",
   "metadata": {},
   "source": [
    "Let's try searching the memory:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_memory_examples(memory: SemanticTextMemory) -> None:\n",
    "    questions = [\"What is my budget for 2024?\", \"What are my savings from 2023?\", \"What are my investments?\"]\n",
    "\n",
    "    for question in questions:\n",
    "        print(f\"Question: {question}\")\n",
    "        result = await memory.search(collection_id, question)\n",
    "        print(f\"Answer: {result[0].text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24764c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "await search_memory_examples(memory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e70c2b22",
   "metadata": {},
   "source": [
    "Let's now revisit the our chat sample from the [previous notebook](04-kernel-arguments-chat.ipynb).\n",
    "If you remember, we used kernel arguments to fill the prompt with a `history` that continuously got populated as we chatted with the bot. Let's add also memory to it!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ed54a32",
   "metadata": {},
   "source": [
    "This is done by using the `TextMemoryPlugin` which exposes the `recall` native function.\n",
    "\n",
    "`recall` takes an input ask and performs a similarity search on the contents that have\n",
    "been embedded in the Memory Store and returns the most relevant memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8549b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def setup_chat_with_memory(\n",
    "    kernel: sk.Kernel,\n",
    "    service_id: str,\n",
    ") -> sk.KernelFunction:\n",
    "    prompt = \"\"\"\n",
    "    ChatBot can have a conversation with you about any topic.\n",
    "    It can give explicit instructions or say 'I don't know' if\n",
    "    it does not have an answer.\n",
    "\n",
    "    Information about me, from previous conversations:\n",
    "    - {{recall 'budget by year'}} What is my budget for 2024?\n",
    "    - {{recall 'savings from previous year'}} What are my savings from 2023?\n",
    "    - {{recall 'investments'}} What are my investments?\n",
    "\n",
    "    {{$request}}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    prompt_template_config = PromptTemplateConfig(\n",
    "        template=prompt,\n",
    "        execution_settings={\n",
    "            service_id: kernel.get_service(service_id).get_prompt_execution_settings_class()(service_id=service_id)\n",
    "        },\n",
    "    )\n",
    "\n",
    "    chat_func = kernel.create_function_from_prompt(prompt_template_config=prompt_template_config)\n",
    "\n",
    "    return chat_func"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ac62457",
   "metadata": {},
   "source": [
    "The `RelevanceParam` is used in memory search and is a measure of the relevance score from 0.0 to 1.0, where 1.0 means a perfect match. We encourage users to experiment with different values.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "645b55a1",
   "metadata": {},
   "source": [
    "Now that we've included our memories, let's chat!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75267a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(kernel: sk.Kernel, chat_func: sk.KernelFunction) -> bool:\n",
    "    try:\n",
    "        user_input = input(\"User:> \")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "    except EOFError:\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "\n",
    "    if user_input == \"exit\":\n",
    "        print(\"\\n\\nExiting chat...\")\n",
    "        return False\n",
    "\n",
    "    answer = await kernel.invoke(chat_func, request=user_input)\n",
    "\n",
    "    print(f\"ChatBot:> {answer}\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3875a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Populating memory...\")\n",
    "await populate_memory(memory)\n",
    "\n",
    "print(\"Asking questions... (manually)\")\n",
    "await search_memory_examples(memory)\n",
    "\n",
    "print(\"Setting up a chat (with memory!)\")\n",
    "chat_func = await setup_chat_with_memory(kernel, chat_service_id)\n",
    "\n",
    "print(\"Begin chatting (type 'exit' to exit):\\n\")\n",
    "print(\n",
    "    \"Welcome to the chat bot!\\\n",
    "    \\n  Type 'exit' to exit.\\\n",
    "    \\n  Try asking a question about your finances (i.e. \\\"talk to me about my finances\\\").\"\n",
    ")\n",
    "chatting = True\n",
    "while chatting:\n",
    "    chatting = await chat(kernel, chat_func)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a51542b",
   "metadata": {},
   "source": [
    "### Adding documents to your memory\n",
    "\n",
    "Many times in your applications you'll want to bring in external documents into your memory. Let's see how we can do this using our VolatileMemoryStore.\n",
    "\n",
    "Let's first get some data using some of the links in the Semantic Kernel repo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_files = {}\n",
    "github_files[\n",
    "    \"https://github.com/microsoft/semantic-kernel/blob/main/README.md\"\n",
    "] = \"README: Installation, getting started, and how to contribute\"\n",
    "github_files[\n",
    "    \"https://github.com/microsoft/semantic-kernel/blob/main/dotnet/notebooks/02-running-prompts-from-file.ipynb\"\n",
    "] = \"Jupyter notebook describing how to pass prompts from a file to a semantic plugin or function\"\n",
    "github_files[\n",
    "    \"https://github.com/microsoft/semantic-kernel/blob/main/dotnet/notebooks/00-getting-started.ipynb\"\n",
    "] = \"Jupyter notebook describing how to get started with the Semantic Kernel\"\n",
    "github_files[\n",
    "    \"https://github.com/microsoft/semantic-kernel/tree/main/samples/plugins/ChatPlugin/ChatGPT\"\n",
    "] = \"Sample demonstrating how to create a chat plugin interfacing with ChatGPT\"\n",
    "github_files[\n",
    "    \"https://github.com/microsoft/semantic-kernel/blob/main/dotnet/src/SemanticKernel/Memory/Volatile/VolatileMemoryStore.cs\"\n",
    "] = \"C# class that defines a volatile embedding store\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75f3ea5e",
   "metadata": {},
   "source": [
    "Now let's add these files to our VolatileMemoryStore using `SaveReferenceAsync`. We'll separate these memories from the chat memories by putting them in a different collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170e7142",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_collection_name = \"SKGitHub\"\n",
    "print(\"Adding some GitHub file URLs and their descriptions to a volatile Semantic Memory.\")\n",
    "i = 0\n",
    "for entry, value in github_files.items():\n",
    "    await memory.save_reference(\n",
    "        collection=memory_collection_name,\n",
    "        description=value,\n",
    "        text=value,\n",
    "        external_id=entry,\n",
    "        external_source_name=\"GitHub\",\n",
    "    )\n",
    "    i += 1\n",
    "    print(\"  URL {} saved\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143911c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"I love Jupyter notebooks, how should I get started?\"\n",
    "print(\"===========================\\n\" + \"Query: \" + ask + \"\\n\")\n",
    "\n",
    "memories = await memory.search(memory_collection_name, ask, limit=5, min_relevance_score=0.77)\n",
    "\n",
    "i = 0\n",
    "for memory in memories:\n",
    "    i += 1\n",
    "    print(f\"Result {i}:\")\n",
    "    print(\"  URL:     : \" + memory.id)\n",
    "    print(\"  Title    : \" + memory.description)\n",
    "    print(\"  Relevance: \" + str(memory.relevance))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59294dac",
   "metadata": {},
   "source": [
    "Now you might be wondering what happens if you have so much data that it doesn't fit into your RAM? That's where you want to make use of an external Vector Database made specifically for storing and retrieving embeddings. Fortunately, semantic kernel makes this easy thanks to an extensive list of available connectors. In the following section, we will connect to an existing Azure AI Search service that we will use as an external Vector Database to store and retrieve embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fdfa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.memory.azure_cognitive_search import (\n",
    "    AzureCognitiveSearchMemoryStore,\n",
    ")\n",
    "\n",
    "azure_ai_search_api_key, azure_ai_search_url = sk.azure_aisearch_settings_from_dot_env()\n",
    "\n",
    "acs_memory_store = AzureCognitiveSearchMemoryStore(\n",
    "    vector_size=1536,\n",
    "    search_endpoint=azure_ai_search_url,\n",
    "    admin_key=azure_ai_search_api_key,\n",
    ")\n",
    "\n",
    "memory = SemanticTextMemory(storage=acs_memory_store, embeddings_generator=embedding_gen)\n",
    "kernel.import_plugin_from_object(TextMemoryPlugin(memory), \"TextMemoryPluginACS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f9e83b",
   "metadata": {},
   "source": [
    "The implementation of Semantic Kernel allows to easily swap memory store for another. Here, we will re-use the functions we initially created for `VolatileMemoryStore` with our new external Vector Store leveraging Azure AI Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3da7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "await populate_memory(memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbe830",
   "metadata": {},
   "source": [
    "Let's now try to query from Azure AI Search!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "await search_memory_examples(memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have laid the foundation which will allow us to store an arbitrary amount of data in an external Vector Store above and beyond what could fit in memory at the expense of a little more latency.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
